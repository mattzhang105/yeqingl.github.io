<div id="main">
  <div class="title building-bridge">
    <h1>Building Bridges</h1>
  </div>
  <div>
    <h4>UX Design</h4>
    <p>A mobile app that helps children with developmental disabilities identify and express emotions.</p>
  </div>
  <section class="content abstract row">
    <div class="col-xs-3">
      <h4 class="d-t">Date</h4>
      <p>Jan 2016<br />- Mar 2016</p>
    </div>
    <div class="col-xs-3">
      <h4 class="d-t">My Contribution</h4>
      <p>
        Research<br />UX Design
      </p>
    </div>
    <div class="col-xs-3">
      <h4 class="d-t">Deliverables</h4>
      <p><a class="demo-btn" data-toggle="modal" data-target="#myModal">View Demo</a></p>
      <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel">
        <div class="modal-dialog" role="document">
          <div class="modal-content">
            <div class="modal-header">
              <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
              <h4 class="modal-title" id="myModalLabel">Interactive Mockup</h4>
            </div>
            <div class="modal-body">
              <iframe src="https://marvelapp.com/1cd30c7?emb=1" width="300" height="501" allowTransparency="true" frameborder="0"></iframe>
            </div>
            <div class="modal-footer">
              <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
            </div>
          </div>
        </div>
      </div>  
    </div>
    <div class="col-xs-3">
      <h4 class="d-t">Tools</h4>
      <p>Axure<br />Illustrator<br />Marvel</p>
    </div>
  </section>
  <section class="content c2">
    <h3>Problem</h3>
    <p>
      Some children who struggle with either or both areas of development are often <strong>unable to understand and express their emotions</strong>. The lack of language makes each emotion far less concrete -- instead it becomes an unknown, nebulous feeling. These strong, unlabelled emotions can be very frightening and frustrating, causing emotional meltdowns and destructive behavior.
    </p>
  </section>
  <section class="content c2">
    <h3>Solution</h3>
    <p>
      We created a mobile application <u id="mobile1"><strong><sub>(?)</sub></strong></u><span id="mobile">Mobile devices have less environmental constraints and their sizes are suitable for small hands.</span> to help 2-to-3-year old children <u id="age1"><strong><sub>(?)</sub></strong></u><span id="age">Between 2 and 3 years, children are making giant leaps in terms of labeling and understanding feelings.</span> who struggle in their social and emotional development learn to associate language and emotion. Under the assistance of adults, children learn to label emotions through the app’s <strong>interactive activities with high quality audio and visual feedback</strong>.
    </p>
    <img src="templates/bridge/solution.png" width="90%" />
  </section>
  <section class="content c2">
    <h3>Process</h3>
    <h4>- Research -</h4>
    <p><strong>Interview Takeaways</strong></p>
    <p>
      We were not able to directly interact with special needs children and their parents, so we interviewed parents with normal young children instead. I had an interview with Georgina, a mother of an 18-month old boy. Here are some of my takeaways:
    </p>
    <p>
      &#9679; In order to teach her son recognize emotions, Georgina intentionally exaggerates her facial expressions when she talks to her son.<br />&#9679; She uses simple words and repeats them a lot.<br />&#9679; She finds cards with cartoon characters are less effective in helping her son associate them with real life expressions.<br />&#9679; At about 6 to 8 months old, her son showed consciousness of emotions and started to form concepts. At 12 months old, he could recognize a few emotions.
    </p>
    <p><strong>Competitive Analysis</strong></p>
    <p>
      Look At Me is an application developed by Samsung that aims to improve socialization skills for autistic children. The interactions between Look At Me and its users involve sound, illustrations, and camera, which effectively creates an engaging environment. The interface design of this application is cute and appropriate for children. However, it has some shortcomings that our group should notice. The language overall is clear and concise, but involves difficult vocabulary and the amount of text is too much for our targeted user. Its function is merely around encouraging the user to make more eye contact. Few practices designed for improving expressing ability. Also, the eye contact is different from looking into the camera, and it may be difficult for children with learning abilities to draw the connection between a camera lens and human eyes.
    </p>
    <img src="templates/bridge/samsung.png" width="40%" />
    <p>
      Considering the age and knowledge of our targeted user and our design goal, <strong>our ideal product should be fun, intuitive, and contain as less vocabulary as possible</strong>.
    </p>
    <h4>- Persona & Scenario -</h4>
    <img src="templates/bridge/persona.png" width="60%" />
    <p>
      After witnessing Maggie become overwhelmed and have an emotional breakdown when another child begins crying, her mother downloads the app per the recommendation of her pediatrician. Over the course of a few months, however, she begins to associate different words with expressions and reactions, due to the pattern recognition the app attempts to instill.
    </p>
    <p>
      One day, Maggie goes to the Kindering Center as usual. When she is playing with a train, we is trapped by a little boy. Maggie sits on the ground and begins to cry. A volunteer comes to her and tries to console her. This time, instead of being completely inconsolable, she says the word “sad,” then continues to cry.
    </p>
    <h4>- Brainstorm & Sketches -</h4>
    <p>
      Our group sketches were generated based on our individual sketches. <strong>We designed two activities -- a “grid mode” and a “face mode.”</strong>
    </p>
    <p>
      &#9679; The grids would show an array of facial expressions -- when tapped a video of a short scenario involving the corresponding emotion would play.<br />&#9679; The “face mode” activity would ask the child to imitate a facial expression, and would use a front-facing camera to determine whether the child was making the correct expression.
    </p>
    <p>
      After consolidating our initial ideas regarding the two activities, we thought up <strong>a settings page that would alter the number of emotions the children would learn in the activities</strong>.
    </p>
    <img src="templates/bridge/sketch.jpg" width="90%" />
    <h4>- Storyboard -</h4>
    <p>Two storyboards for the two activities of our app.</p>
    <div class="row">
      <img class="col-sm-6" src="templates/bridge/storyboard1.jpg" width="100%" />
      <img class="col-sm-6" src="templates/bridge/storyboard2.jpg" width="100%" />
    </div>
    <h4>- Prototype -</h4>
    <img src="templates/bridge/original-prototype.jpg" width="100%" />
    <h4>- Wireframes -</h4>
    <img src="templates/bridge/w-feel.jpg" width="60%" />
    <h4>- High Fidelity Mockup -</h4>
    <img src="templates/bridge/critique.jpg" width="50%" />
    <img src="templates/bridge/mockup.png" width="50%" />
  </section>
  <div id="prev">
    <p><a ui-sref="home.projects.aqua"><img src="img/left.png" width="50px" /></a></p>
  </div>
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75575300-1', 'auto');
  ga('send', 'pageview');
</script>